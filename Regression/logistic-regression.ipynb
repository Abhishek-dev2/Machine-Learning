{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('winequality-red.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n"
     ]
    }
   ],
   "source": [
    "print(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = df.drop('quality', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = inp.values\n",
    "y = output.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_custom_score(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    scores =  precision_recall_fscore_support(y, y_pred, average=None)\n",
    "    print(\"precision per class: %s\" %(str(scores[0].tolist())))\n",
    "    print(\"recall per class: %s\" %(str(scores[1].tolist())))\n",
    "    print(\"fscore per class: %s\" %(str(scores[2].tolist())))\n",
    "    print(\"****************\")\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision per class: [0.0, 0.0, 0.5511111111111111, 0.5217391304347826, 0.6, 0.0]\n",
      "recall per class: [0.0, 0.0, 0.9051094890510949, 0.375, 0.075, 0.0]\n",
      "fscore per class: [0.0, 0.0, 0.6850828729281768, 0.43636363636363634, 0.13333333333333333, 0.0]\n",
      "****************\n",
      "precision per class: [0.0, 0.0, 0.5813953488372093, 0.46923076923076923, 0.42105263157894735, 0.0]\n",
      "recall per class: [0.0, 0.0, 0.7352941176470589, 0.4765625, 0.2, 0.0]\n",
      "fscore per class: [0.0, 0.0, 0.6493506493506493, 0.4728682170542636, 0.2711864406779661, 0.0]\n",
      "****************\n",
      "precision per class: [0.0, 0.0, 0.6748466257668712, 0.5364238410596026, 0.2857142857142857, 0.0]\n",
      "recall per class: [0.0, 0.0, 0.8088235294117647, 0.6328125, 0.05, 0.0]\n",
      "fscore per class: [0.0, 0.0, 0.7357859531772575, 0.5806451612903226, 0.0851063829787234, 0.0]\n",
      "****************\n",
      "precision per class: [0.0, 0.0, 0.7241379310344828, 0.5263157894736842, 0.5, 0.0]\n",
      "recall per class: [0.0, 0.0, 0.6176470588235294, 0.7874015748031497, 0.15, 0.0]\n",
      "fscore per class: [0.0, 0.0, 0.6666666666666667, 0.6309148264984228, 0.23076923076923075, 0.0]\n",
      "****************\n",
      "precision per class: [0.0, 0.0, 0.704, 0.5208333333333334, 0.0, 0.0]\n",
      "recall per class: [0.0, 0.0, 0.6470588235294118, 0.7874015748031497, 0.0, 0.0]\n",
      "fscore per class: [0.0, 0.0, 0.6743295019157088, 0.6269592476489029, 0.0, 0.0]\n",
      "****************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ragha\\Miniconda3\\envs\\for_ml\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ragha\\Miniconda3\\envs\\for_ml\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ragha\\Miniconda3\\envs\\for_ml\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ragha\\Miniconda3\\envs\\for_ml\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ragha\\Miniconda3\\envs\\for_ml\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "scores = cross_val_score(model, X, y, scoring= my_custom_score, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3, 4, 5, 6, 7, 8}\n"
     ]
    }
   ],
   "source": [
    "print(set(y.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   9   1   0   0]\n",
      " [  0   0  37  15   1   0]\n",
      " [  0   0 519 160   2   0]\n",
      " [  0   0 232 397   9   0]\n",
      " [  0   0  13 169  17   0]\n",
      " [  0   0   0  13   5   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y, y_pred, labels=[3,4,5,6,7,8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:for_ml]",
   "language": "python",
   "name": "conda-env-for_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
