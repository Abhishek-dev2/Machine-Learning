{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BCLL.txt', sep='\\t', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('IDENTIFIER', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(point1:'numpy array', point2:'numpy array'):\n",
    "    return np.sqrt(np.sum((point1 - point2)**2)) #no use of zero index which is id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_best_centroid(node, centroid_list:'dictionary of centroids id, value'):\n",
    "    mini = math.inf\n",
    "    for key, centroid in centroid_list.items():\n",
    "        distance = get_distance(node, centroid)\n",
    "        if distance < mini:\n",
    "            mini = distance\n",
    "            best_id = key\n",
    "        \n",
    "    return best_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_centroids(node_id_to_cluster_id:'node_id:cluster id', node_id_to_node_features:'node id: node vector'):\n",
    "    cluster_id_to_node_list = defaultdict(list)\n",
    "    for node_id, cluster_id in node_id_to_cluster_id.items():\n",
    "        cluster_id_to_node_list[cluster_id].append(node_id_to_node_features[node_id])\n",
    "    centroid_list_new = defaultdict(list)\n",
    "    for cluster_id, list_of_nodes in cluster_id_to_node_list.items():\n",
    "        centroid_list_new[cluster_id] = sum(list_of_nodes)/len(list_of_nodes)\n",
    "    del cluster_id_to_node_list\n",
    "    return centroid_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def K_means(k, X):\n",
    "    node_id_to_node_features = defaultdict(list) # node id : node features\n",
    "    centroid_dictionary = defaultdict(list) # cluster id: node features\n",
    "    node_id_to_cluster_id = defaultdict(list) # node id: node features\n",
    "\n",
    "    for node in X:\n",
    "        id_ref = node[0]\n",
    "        node_id_to_node_features[id_ref] = node[1:]\n",
    "\n",
    "    indexes = [i for i in range(len(X))]\n",
    "    random.shuffle(indexes)\n",
    "    for i in range(k):\n",
    "        centroid_dictionary[i] = copy.deepcopy(X[indexes[i]][1:])\n",
    "\n",
    "    while True:\n",
    "        count =0\n",
    "        for node_id, node_features in node_id_to_node_features.items():\n",
    "            id_best_centroid = get_id_best_centroid(node_features,centroid_dictionary)\n",
    "                \n",
    "            if node_id_to_cluster_id[node_id]!=id_best_centroid:\n",
    "                count+=1\n",
    "            node_id_to_cluster_id[node_id] = id_best_centroid\n",
    "        if count==0:\n",
    "            return centroid_dictionary, node_id_to_cluster_id, node_id_to_node_features\n",
    "        centroid_dictionary_new = get_new_centroids(node_id_to_cluster_id, node_id_to_node_features)      \n",
    "        centroid_dictionary = copy.deepcopy(centroid_dictionary_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_clusters = [i for i in range(2, int(math.sqrt(len(X))))]\n",
    "random.shuffle(total_clusters)\n",
    "for k in total_clusters[:10]:\n",
    "    print(\"Starting K means for k={}\".format(k))\n",
    "    cluster_id_to_centroid_features, node_id_to_cluster_id, node_id_to_node_features = K_means(k, X)\n",
    "    print(\"K means finished!. Starting writing i\")\n",
    "    if not os.path.exists(os.path.dirname('cluster_number_{}'.format(k))):\n",
    "        os.makedirs('clusters/cluster_number_'+str(k))\n",
    "\n",
    "    for node_id, cluster_id in node_id_to_cluster_id.items():\n",
    "        with open('clusters/cluster_number_{}/cluster{}.txt'.format(k, cluster_id+1), 'a+') as f:\n",
    "            text = str(node_id)+'\\n'\n",
    "            f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:for_ml]",
   "language": "python",
   "name": "conda-env-for_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
